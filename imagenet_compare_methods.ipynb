{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imagenet_compare_methods.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "_Bj-5uvUKegH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Compare analyzers on ImageNet"
      ]
    },
    {
      "metadata": {
        "id": "vWy7igINKsp1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1229
        },
        "outputId": "5afb723d-fe74-4299-f1f0-657704ab9c7c"
      },
      "cell_type": "code",
      "source": [
        "!wget http://farm4.static.flickr.com/3142/2592291184_71735af93e.jpg -O n07720875_13.jpg\n",
        "!wget http://farm1.static.flickr.com/36/122398209_7915b8bcdb.jpg -O n02799071_190.jpg\n",
        "!wget http://farm1.static.flickr.com/165/329702023_cb41c65e84.jpg -O n07615774_348.jpg\n",
        "!wget http://farm3.static.flickr.com/2207/1675176906_8f98de2f96.jpg -O n01978287_43.jpg\n",
        "#!wget http://polardiscovery.whoi.edu/arctic/images/timeline-pargo.jpg -O n04347754_440.jpg\n",
        "!wget http://farm2.static.flickr.com/1292/1155177675_d0d23ede2a.jpg -O n02906734_320.jpg\n",
        "!wget http://farm3.static.flickr.com/2123/2347434732_23d10f8587.jpg -O n02667093_96.jpg"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-29 15:52:01--  http://farm4.static.flickr.com/3142/2592291184_71735af93e.jpg\n",
            "Resolving farm4.static.flickr.com (farm4.static.flickr.com)... 74.6.47.80\n",
            "Connecting to farm4.static.flickr.com (farm4.static.flickr.com)|74.6.47.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 132991 (130K) [image/jpeg]\n",
            "Saving to: ‘n07720875_13.jpg’\n",
            "\n",
            "\rn07720875_13.jpg      0%[                    ]       0  --.-KB/s               \rn07720875_13.jpg    100%[===================>] 129.87K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2018-11-29 15:52:01 (2.28 MB/s) - ‘n07720875_13.jpg’ saved [132991/132991]\n",
            "\n",
            "--2018-11-29 15:52:03--  http://farm1.static.flickr.com/36/122398209_7915b8bcdb.jpg\n",
            "Resolving farm1.static.flickr.com (farm1.static.flickr.com)... 74.6.47.80\n",
            "Connecting to farm1.static.flickr.com (farm1.static.flickr.com)|74.6.47.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 136473 (133K) [image/jpeg]\n",
            "Saving to: ‘n02799071_190.jpg’\n",
            "\n",
            "n02799071_190.jpg   100%[===================>] 133.27K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2018-11-29 15:52:03 (2.25 MB/s) - ‘n02799071_190.jpg’ saved [136473/136473]\n",
            "\n",
            "--2018-11-29 15:52:04--  http://farm1.static.flickr.com/165/329702023_cb41c65e84.jpg\n",
            "Resolving farm1.static.flickr.com (farm1.static.flickr.com)... 74.6.47.80\n",
            "Connecting to farm1.static.flickr.com (farm1.static.flickr.com)|74.6.47.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 135503 (132K) [image/jpeg]\n",
            "Saving to: ‘n07615774_348.jpg’\n",
            "\n",
            "n07615774_348.jpg   100%[===================>] 132.33K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2018-11-29 15:52:04 (2.02 MB/s) - ‘n07615774_348.jpg’ saved [135503/135503]\n",
            "\n",
            "--2018-11-29 15:52:06--  http://farm3.static.flickr.com/2207/1675176906_8f98de2f96.jpg\n",
            "Resolving farm3.static.flickr.com (farm3.static.flickr.com)... 74.6.47.80\n",
            "Connecting to farm3.static.flickr.com (farm3.static.flickr.com)|74.6.47.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 123722 (121K) [image/jpeg]\n",
            "Saving to: ‘n01978287_43.jpg’\n",
            "\n",
            "n01978287_43.jpg    100%[===================>] 120.82K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2018-11-29 15:52:06 (1.79 MB/s) - ‘n01978287_43.jpg’ saved [123722/123722]\n",
            "\n",
            "--2018-11-29 15:52:07--  http://farm2.static.flickr.com/1292/1155177675_d0d23ede2a.jpg\n",
            "Resolving farm2.static.flickr.com (farm2.static.flickr.com)... 74.6.47.80\n",
            "Connecting to farm2.static.flickr.com (farm2.static.flickr.com)|74.6.47.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168896 (165K) [image/jpeg]\n",
            "Saving to: ‘n02906734_320.jpg’\n",
            "\n",
            "n02906734_320.jpg   100%[===================>] 164.94K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2018-11-29 15:52:07 (2.10 MB/s) - ‘n02906734_320.jpg’ saved [168896/168896]\n",
            "\n",
            "--2018-11-29 15:52:09--  http://farm3.static.flickr.com/2123/2347434732_23d10f8587.jpg\n",
            "Resolving farm3.static.flickr.com (farm3.static.flickr.com)... 74.6.47.80\n",
            "Connecting to farm3.static.flickr.com (farm3.static.flickr.com)|74.6.47.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 159664 (156K) [image/jpeg]\n",
            "Saving to: ‘n02667093_96.jpg’\n",
            "\n",
            "n02667093_96.jpg    100%[===================>] 155.92K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2018-11-29 15:52:09 (1.82 MB/s) - ‘n02667093_96.jpg’ saved [159664/159664]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nMaJz3Q0K-Cd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "b44a3089-f7bb-4d61-e551-2e1226b20523"
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/albermax/innvestigate"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/albermax/innvestigate\n",
            "  Cloning https://github.com/albermax/innvestigate to /tmp/pip-req-build-rfgoexzv\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from innvestigate==1.0.5) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from innvestigate==1.0.5) (2.8.0)\n",
            "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (from innvestigate==1.0.5) (2.2.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from innvestigate==1.0.5) (1.14.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from innvestigate==1.0.5) (4.0.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from innvestigate==1.0.5) (3.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from innvestigate==1.0.5) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->innvestigate==1.0.5) (1.11.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->innvestigate==1.0.5) (1.0.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->innvestigate==1.0.5) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->innvestigate==1.0.5) (1.0.5)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->innvestigate==1.0.5) (0.46)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->innvestigate==1.0.5) (18.2.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->innvestigate==1.0.5) (1.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->innvestigate==1.0.5) (40.6.2)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->innvestigate==1.0.5) (4.3.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->innvestigate==1.0.5) (1.2.1)\n",
            "Requirement already satisfied: pluggy>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytest->innvestigate==1.0.5) (0.8.0)\n",
            "Building wheels for collected packages: innvestigate\n",
            "  Running setup.py bdist_wheel for innvestigate ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-j0o1su_4/wheels/f9/54/80/d9a6e23156696217cb721897eefce270d3ad014dbb4f16c835\n",
            "Successfully built innvestigate\n",
            "Installing collected packages: innvestigate\n",
            "Successfully installed innvestigate-1.0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "--JUCemQKegO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this notebook we show how one can use **iNNvestigate** to analyze the prediction of ImageNet-models! To do so we will load a network from the keras.applications module and analyze prediction on some images!\n",
        "\n",
        "Parts of the code that do not contribute to the main focus are outsourced into utility modules. To learn more about the basic usage of **iNNvestigate** have look into this notebook: [Introduction to iNNvestigate](introduction.ipynb) and [Comparing methods on MNIST](mnist_method_comparison.ipynb)\n",
        "\n",
        "-----\n",
        "\n",
        "**To use this notebook please download the example images using the following script:**\n",
        "\n",
        "`innvestigate/examples/images/wget_imagenet_2011_samples.sh`"
      ]
    },
    {
      "metadata": {
        "id": "H0nRRHvxKegR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {
        "id": "Qe4jsY1yKegW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "62e8564d-8bd2-4069-da36-53208716d7b7"
      },
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l3bv_PNDLdAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "27e0244c-76f2-4224-dd2b-1ea9f534a7a0"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/albermax/innvestigate.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'innvestigate'...\n",
            "remote: Enumerating objects: 236, done.\u001b[K\n",
            "remote: Counting objects: 100% (236/236), done.\u001b[K\n",
            "remote: Compressing objects: 100% (125/125), done.\u001b[K\n",
            "remote: Total 4040 (delta 137), reused 194 (delta 111), pack-reused 3804\u001b[K\n",
            "Receiving objects: 100% (4040/4040), 27.39 MiB | 23.10 MiB/s, done.\n",
            "Resolving deltas: 100% (2799/2799), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "og1Ar7nZKegh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline  \n",
        "\n",
        "import imp\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import keras\n",
        "import keras.backend\n",
        "import keras.models\n",
        "#import innvestigate.examples.utils.py as eutils\n",
        "#import innvestigate.examples.utils_imagenet.py as imgnetutils\n",
        "\n",
        "import innvestigate\n",
        "import innvestigate.applications.imagenet\n",
        "import innvestigate.utils as iutils\n",
        "\n",
        "# Use utility libraries to focus on relevant iNNvestigate routines.\n",
        "#eutils = imp.load_source(\"innvestigate/examples/utils.py\")\n",
        "#imgnetutils = imp.load_source(\"innvestigate/examples\",\"/utils_imagenet.py\")\n",
        "eutils = imp.load_source(\"utils\", \"innvestigate/examples/utils.py\")\n",
        "imgnetutils = imp.load_source(\"utils_imagenet\", \"innvestigate/examples/utils_imagenet.py\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AyUi_r9rKegu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model"
      ]
    },
    {
      "metadata": {
        "id": "7Y4WBnO0Kegx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this demo use the VGG16-model, which uses ReLU activation layers."
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "zc9-3lZJKeg0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "0d4686fe-cd93-4f45-d694-030f8ee81276"
      },
      "cell_type": "code",
      "source": [
        "# Load the model definition.\n",
        "tmp = getattr(innvestigate.applications.imagenet, os.environ.get(\"NETWORKNAME\", \"vgg16\"))\n",
        "net = tmp(load_weights=True, load_patterns=\"relu\")\n",
        "\n",
        "# Build the model.\n",
        "model = keras.models.Model(inputs=net[\"in\"], outputs=net[\"sm_out\"])\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
        "\n",
        "# Handle input depending on model and backend.\n",
        "channels_first = keras.backend.image_data_format() == \"channels_first\"\n",
        "color_conversion = \"BGRtoRGB\" if net[\"color_coding\"] == \"BGR\" else None"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 13s 0us/step\n",
            "Downloading data from https://www.dropbox.com/s/15lip81fzvbgkaa/vgg16_pattern_type_relu_tf_dim_ordering_tf_kernels.npz?dl=1\n",
            "553385984/553380098 [==============================] - 13s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l7THWPDjsGFx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mv n07720875_13.jpg innvestigate/examples/images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y2_YQjFAKeg7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data"
      ]
    },
    {
      "metadata": {
        "id": "EkF4TlmVKeg9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we load some example images and preprocess them to fit the input size model.\n",
        "\n",
        "To analyze your own example images, just add them to `innvestigate/examples/images`."
      ]
    },
    {
      "metadata": {
        "id": "3MHWKxH-KehA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get some example test set images.\n",
        "images, label_to_class_name = eutils.get_imagenet_data(net[\"image_shape\"][0])\n",
        "\n",
        "if not len(images):\n",
        "    raise Exception(\"Please download the example images using: \"\n",
        "                    \"'innvestigate/examples/images/wget_imagenet_2011_samples.sh'\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xuoK4XRxKehK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Analysis"
      ]
    },
    {
      "metadata": {
        "id": "8KbZ2AXvKehN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we will set up a list of analysis methods by preparing tuples containing the methods' string identifiers used by `innvestigate.analyzer.create_analyzer(...)`, some optional parameters, a post processing choice for visualizing the computed analysis and a title for the figure to render. Analyzers can be deactivated by simply commenting the corresponding lines, or added by creating a new tuple as below.\n",
        "\n",
        "For a full list of methods refer to the dictionary `investigate.analyzer.analyzers`.\n",
        "\n",
        "Note: Should you run into resource trouble, e.g. you are running that notebook on a computer without GPU or with only limited GPU memory, consider deactivating one or more analyzers by commenting the corresponding lines in the next cell."
      ]
    },
    {
      "metadata": {
        "id": "Ik5g2NnmKehP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "patterns = net[\"patterns\"]\n",
        "input_range = net[\"input_range\"]\n",
        "\n",
        "noise_scale = (input_range[1]-input_range[0]) * 0.1\n",
        "\n",
        "# Methods we use and some properties.\n",
        "methods = [\n",
        "    # NAME                    OPT.PARAMS                POSTPROC FXN                TITLE\n",
        "    # Show input.\n",
        "    (\"input\",                 {},                       imgnetutils.image,         \"Input\"),\n",
        "\n",
        "    # Function\n",
        "    (\"gradient\",              {\"postprocess\": \"abs\"},   imgnetutils.graymap,       \"Gradient\"),\n",
        "    (\"smoothgrad\",            {\"augment_by_n\": 64,\n",
        "                               \"noise_scale\": noise_scale,\n",
        "                               \"postprocess\": \"square\"},imgnetutils.graymap,       \"SmoothGrad\"),\n",
        "\n",
        "    # Signal\n",
        "    (\"deconvnet\",             {},                       imgnetutils.bk_proj,       \"Deconvnet\"),\n",
        "    (\"guided_backprop\",       {},                       imgnetutils.bk_proj,       \"Guided Backprop\",),\n",
        "    (\"pattern.net\",           {\"patterns\": patterns},   imgnetutils.bk_proj,       \"PatternNet\"),\n",
        "\n",
        "    # Interaction\n",
        "    (\"pattern.attribution\",   {\"patterns\": patterns},   imgnetutils.heatmap,       \"PatternAttribution\"),\n",
        "    (\"deep_taylor.bounded\",   {\"low\": input_range[0],\n",
        "                               \"high\": input_range[1]}, imgnetutils.heatmap,       \"DeepTaylor\"),\n",
        "    (\"input_t_gradient\",      {},                       imgnetutils.heatmap,       \"Input * Gradient\"),\n",
        "    (\"integrated_gradients\",  {\"reference_inputs\": input_range[0],\n",
        "                               \"steps\": 64},            imgnetutils.heatmap,       \"Integrated Gradients\"),\n",
        "    (\"lrp.z\",                 {},                       imgnetutils.heatmap,       \"LRP-Z\"),\n",
        "    (\"lrp.epsilon\",           {\"epsilon\": 1},           imgnetutils.heatmap,       \"LRP-Epsilon\"),\n",
        "    (\"lrp.sequential_preset_a_flat\",{\"epsilon\": 1},     imgnetutils.heatmap,       \"LRP-PresetAFlat\"),\n",
        "    (\"lrp.sequential_preset_b_flat\",{\"epsilon\": 1},     imgnetutils.heatmap,       \"LRP-PresetBFlat\"),\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CTxM2xPCKehb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The main loop below will now instantiate the analyzer objects based on the loaded/trained model and the analyzers' parameterizations above and compute the analyses."
      ]
    },
    {
      "metadata": {
        "id": "eyNLrAmgKehi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create model without trailing softmax\n",
        "model_wo_softmax = iutils.keras.graph.model_wo_softmax(model)\n",
        "\n",
        "# Create analyzers.\n",
        "analyzers = []\n",
        "for method in methods:\n",
        "    try:\n",
        "        analyzer = innvestigate.create_analyzer(method[0],        # analysis method identifier\n",
        "                                                model_wo_softmax, # model without softmax output\n",
        "                                                **method[1])      # optional analysis parameters\n",
        "    except innvestigate.NotAnalyzeableModelException:\n",
        "        # Not all methods work with all models.\n",
        "        analyzer = None\n",
        "    analyzers.append(analyzer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OCJFSbssKehv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we analyze each image with the different analyzers:"
      ]
    },
    {
      "metadata": {
        "id": "dGDuRhmlKehy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "analysis = np.zeros([len(images), len(analyzers)]+net[\"image_shape\"]+[3])\n",
        "text = []\n",
        "\n",
        "for i, (x, y) in enumerate(images):\n",
        "    # Add batch axis.\n",
        "    x = x[None, :, :, :]\n",
        "    x_pp = imgnetutils.preprocess(x, net)\n",
        "\n",
        "    # Predict final activations, probabilites, and label.\n",
        "    presm = model_wo_softmax.predict_on_batch(x_pp)[0]\n",
        "    prob = model.predict_on_batch(x_pp)[0]\n",
        "    y_hat = prob.argmax()\n",
        "    \n",
        "    # Save prediction info:\n",
        "    text.append((\"%s\" % label_to_class_name[y],    # ground truth label\n",
        "                 \"%.2f\" % presm.max(),             # pre-softmax logits\n",
        "                 \"%.2f\" % prob.max(),              # probabilistic softmax output  \n",
        "                 \"%s\" % label_to_class_name[y_hat] # predicted label\n",
        "                ))\n",
        "\n",
        "    for aidx, analyzer in enumerate(analyzers):\n",
        "        if methods[aidx][0] == \"input\":\n",
        "            # Do not analyze, but keep not preprocessed input.\n",
        "            a = x/255\n",
        "        elif analyzer:\n",
        "            # Analyze.\n",
        "            a = analyzer.analyze(x_pp)\n",
        "\n",
        "            # Apply common postprocessing, e.g., re-ordering the channels for plotting.\n",
        "            a = imgnetutils.postprocess(a, color_conversion, channels_first)\n",
        "            # Apply analysis postprocessing, e.g., creating a heatmap.\n",
        "            a = methods[aidx][2](a)\n",
        "        else:\n",
        "            a = np.zeros_like(image)\n",
        "        # Store the analysis.\n",
        "        analysis[i, aidx] = a[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ov0h4TIgKeh3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we visualize the analysis results:"
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "IYn5PzidKeh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "75e38999-c2ca-4321-9447-981f0662550a"
      },
      "cell_type": "code",
      "source": [
        "# Prepare the grid as rectengular list\n",
        "grid = [[analysis[i, j] for j in range(analysis.shape[1])]\n",
        "        for i in range(analysis.shape[0])]  \n",
        "# Prepare the labels\n",
        "label, presm, prob, pred = zip(*text)\n",
        "row_labels_left = [('label: {}'.format(label[i]),'pred: {}'.format(pred[i])) for i in range(len(label))]\n",
        "row_labels_right = [('logit: {}'.format(presm[i]),'prob: {}'.format(prob[i])) for i in range(len(label))]\n",
        "col_labels = [''.join(method[3]) for method in methods]\n",
        "\n",
        "# Plot the analysis.\n",
        "eutils.plot_image_grid(grid, row_labels_left, row_labels_right, col_labels,\n",
        "                       file_name=os.environ.get(\"plot_file_name\", None))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c3ebecd3c9bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m grid = [[analysis[i, j] for j in range(analysis.shape[1])]\n\u001b[0;32m----> 2\u001b[0;31m         for i in range(analysis.shape[0])]  \n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Prepare the labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrow_labels_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pred: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'analysis' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "WyQBKn_cKeiE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This figure shows the analysis regarding the *actually predicted* class as computed by the selected analyzers. Each column shows the visualized results for different analyzers and each row shows the analyses wrt to one input sample. To the left of each row, the ground truth label `label` and the predicted label `pred` are show. To the right, the model's probabilistic (softmax) output is shown as `prob` and the logit output just before the terminating softmax layer as `logit`. Note that all analyses have been performed based on the logit output (layer).\n",
        "\n",
        "\n",
        "If you are curious about how **iNNvestigate** performs on *different* ImageNet model, have a look here: [Comparing networks on ImageNet](imagenet_network_comparison.ipynb)"
      ]
    }
  ]
}